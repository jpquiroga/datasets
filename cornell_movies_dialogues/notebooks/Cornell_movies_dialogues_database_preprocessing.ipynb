{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornell movies dialogues dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie_conversations.txt', 'raw_script_urls.txt', 'movie_lines.txt', 'README.txt', 'chameleons.pdf', 'movie_titles_metadata.txt', 'movie_characters_metadata.txt', '.DS_Store']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "DATA_DIR = \"../data/cornell_movie_dialogs_corpus\"\n",
    "PREPROCESSED_DATA_DIR = \"../preprocessed_data\"\n",
    "print(os.listdir(DATA_DIR))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornell Movie-Dialogs Corpus\r\n",
      "\r\n",
      "Distributed together with:\r\n",
      "\r\n",
      "\"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs\"\r\n",
      "Cristian Danescu-Niculescu-Mizil and Lillian Lee\r\n",
      "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, ACL 2011.\r",
      "\r\n",
      "\r\n",
      "(this paper is included in this zip file)\r\n",
      "\r\n",
      "NOTE: If you have results to report on these corpora, please send email to cristian@cs.cornell.edu or llee@cs.cornell.edu so we can add you to our list of people using this data.  Thanks!\r\n",
      "\r\n",
      "\r\n",
      "Contents of this README:\r\n",
      "\r\n",
      "\tA) Brief description\r\n",
      "\tB) Files description\r\n",
      "\tC) Details on the collection procedure\r\n",
      "\tD) Contact\r\n",
      "\r\n",
      "\r\n",
      "A) Brief description:\r\n",
      "\r\n",
      "This corpus contains a metadata-rich collection of fictional conversations extracted from raw movie scripts:\r\n",
      "\r\n",
      "- 220,579 conversational exchanges between 10,292 pairs of movie characters\r\n",
      "- involves 9,035 characters from 617 movies\r\n",
      "- in total 304,713 utterances\r\n",
      "- movie metadata included:\r\n",
      "\t- genres\r\n",
      "\t- release year\r\n",
      "\t- IMDB rating\r\n",
      "\t- number of IMDB votes\r\n",
      "\t- IMDB rating\r\n",
      "- character metadata included:\r\n",
      "\t- gender (for 3,774 characters)\r\n",
      "\t- position on movie credits (3,321 characters)\r\n",
      "\r\n",
      "\r\n",
      "B) Files description:\r\n",
      "\r\n",
      "In all files the field separator is \" +++$+++ \"\r\n",
      "\r\n",
      "- movie_titles_metadata.txt\r\n",
      "\t- contains information about each movie title\r\n",
      "\t- fields: \r\n",
      "\t\t- movieID, \r\n",
      "\t\t- movie title,\r\n",
      "\t\t- movie year, \r\n",
      "\t   \t- IMDB rating,\r\n",
      "\t\t- no. IMDB votes,\r\n",
      " \t\t- genres in the format ['genre1','genre2',�,'genreN']\r\n",
      "\r\n",
      "- movie_characters_metadata.txt\r\n",
      "\t- contains information about each movie character\r\n",
      "\t- fields:\r\n",
      "\t\t- characterID\r\n",
      "\t\t- character name\r\n",
      "\t\t- movieID\r\n",
      "\t\t- movie title\r\n",
      "\t\t- gender (\"?\" for unlabeled cases)\r\n",
      "\t\t- position in credits (\"?\" for unlabeled cases) \r\n",
      "\r\n",
      "- movie_lines.txt\r\n",
      "\t- contains the actual text of each utterance\r\n",
      "\t- fields:\r\n",
      "\t\t- lineID\r\n",
      "\t\t- characterID (who uttered this phrase)\r\n",
      "\t\t- movieID\r\n",
      "\t\t- character name\r\n",
      "\t\t- text of the utterance\r\n",
      "\r\n",
      "- movie_conversations.txt\r\n",
      "\t- the structure of the conversations\r\n",
      "\t- fields\r\n",
      "\t\t- characterID of the first character involved in the conversation\r\n",
      "\t\t- characterID of the second character involved in the conversation\r\n",
      "\t\t- movieID of the movie in which the conversation occurred\r\n",
      "\t\t- list of the utterances that make the conversation, in chronological \r\n",
      "\t\t\torder: ['lineID1','lineID2',�,'lineIDN']\r\n",
      "\t\t\thas to be matched with movie_lines.txt to reconstruct the actual content\r\n",
      "\r\n",
      "- raw_script_urls.txt\r\n",
      "\t- the urls from which the raw sources were retrieved\r\n",
      "\r\n",
      "C) Details on the collection procedure:\r\n",
      "\r\n",
      "We started from raw publicly available movie scripts (sources acknowledged in \r\n",
      "raw_script_urls.txt).  In order to collect the metadata necessary for this study \r\n",
      "and to distinguish between two script versions of the same movie, we automatically\r\n",
      " matched each script with an entry in movie database provided by IMDB (The Internet\r\n",
      " Movie Database; data interfaces available at http://www.imdb.com/interfaces). Some\r\n",
      " amount of manual correction was also involved. When  more than one movie with the same\r\n",
      " title was found in IMBD, the match was made with the most popular title \r\n",
      "(the one that received most IMDB votes)  \r\n",
      "\r\n",
      "After discarding all movies that could not be matched or that had less than 5 IMDB \r\n",
      "votes, we were left with 617 unique titles with metadata including genre, release \r\n",
      "year, IMDB rating and no. of IMDB votes and cast distribution.  We then identified \r\n",
      "the pairs of characters that interact and separated their conversations automatically \r\n",
      "using simple data processing heuristics. After discarding all pairs that exchanged \r\n",
      "less than 5 conversational exchanges there were 10,292 left, exchanging 220,579 \r\n",
      "conversational exchanges (304,713 utterances).  After automatically matching the names \r\n",
      "of the 9,035 involved characters to the list of cast distribution, we used the \r\n",
      "gender of each interpreting actor to infer the fictional gender of a subset of \r\n",
      "3,321 movie characters (we raised the number of gendered 3,774 characters through\r\n",
      " manual annotation). Similarly, we collected the end credit position of a subset \r\n",
      "of 3,321 characters as a proxy for their status.\r\n",
      "\r\n",
      "\r\n",
      "D) Contact:\r\n",
      "\r\n",
      "Please email any questions to: cristian@cs.cornell.edu (Cristian Danescu-Niculescu-Mizil)"
     ]
    }
   ],
   "source": [
    "!cat ../data/cornell_movie_dialogs_corpus/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: no se puede abrir '../input/movie_lines.txt' para lectura: No existe el archivo o el directorio\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1000 ../input/movie_lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parse dialogue lines into pandas data frame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_line(s_line, delim):\n",
    "    res = []\n",
    "    _buff = s_line\n",
    "    while delim in _buff:\n",
    "        _index = _buff.index(delim)\n",
    "        res.append(_buff[:_index].strip())\n",
    "        _buff = _buff[_index+len(delim):].strip()\n",
    "    res.append(_buff)\n",
    "    return res\n",
    "\n",
    "# Test\n",
    "# split_line(\"L578 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ I believe we share an art instructor\", \"+++$+++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_lines_to_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    - movie_lines.txt\n",
    "        - contains the actual text of each utterance\n",
    "        - fields:\n",
    "            - lineID\n",
    "            - characterID (who uttered this phrase)\n",
    "            - movieID\n",
    "            - character name\n",
    "            - text of the utterance\n",
    "    \"\"\"\n",
    "    DELIM = \"+++$+++\"\n",
    "    line_ids = []\n",
    "    character_ids = []\n",
    "    movie_ids = []\n",
    "    character_names = []\n",
    "    utterances = []    \n",
    "    with open(file_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for l in tqdm(f.readlines()):\n",
    "            _parsed_line = split_line(l, DELIM)\n",
    "            line_ids.append(_parsed_line[0])\n",
    "            character_ids.append(_parsed_line[1])\n",
    "            movie_ids.append(_parsed_line[2])\n",
    "            character_names.append(_parsed_line[3])\n",
    "            utterances.append(_parsed_line[4])\n",
    "    res = pd.DataFrame()\n",
    "    res[\"LINE_ID\"] = line_ids\n",
    "    res[\"CHARACTER_ID\"] = character_ids\n",
    "    res[\"MOVIE_ID\"] = movie_ids\n",
    "    res[\"CHARACTER_NAME\"] = character_names\n",
    "    res[\"UTTERANCE\"] = utterances\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aea0027f3934c62a6ae8d771616b259"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie_lines = movie_lines_to_dataframe(DATA_DIR + \"/movie_lines.txt\")\n",
    "# Save to disk\n",
    "df_movie_lines.to_csv(\"movie_lines.csv\")\n",
    "df_movie_lines.to_pickle(\"movie_lines.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LINE_ID           object\n",
       "CHARACTER_ID      object\n",
       "MOVIE_ID          object\n",
       "CHARACTER_NAME    object\n",
       "UTTERANCE         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie_lines.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53M\r\n",
      "drwxr-xr-x 3 wotan wotan 4,0K abr 14 17:53 .\r\n",
      "drwxr-xr-x 5 wotan wotan 4,0K abr 14 15:56 ..\r\n",
      "-rw-r--r-- 1 wotan wotan  23K abr 14 17:53 Cornell_movies_dialogues_database_preprocessng.ipynb\r\n",
      "drwxr-xr-x 2 wotan wotan 4,0K abr 14 15:00 .ipynb_checkpoints\r\n",
      "-rw-r--r-- 1 wotan wotan  26M abr 14 18:38 movie_lines.csv\r\n",
      "-rw-r--r-- 1 wotan wotan  27M abr 14 18:38 movie_lines.pick\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Translate to Spanish__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16838300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of characters in utterances\n",
    "def count_chars(texts_list):\n",
    "    count = 0\n",
    "    for l in texts_list:\n",
    "        count += len(l)\n",
    "    return count\n",
    "\n",
    "count_chars(df_movie_lines.UTTERANCE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the first 2 million chars\n",
    "def get_max_index(texts_list, max_length, start_index=0):\n",
    "    count = 0\n",
    "    index = start_index\n",
    "    for l in texts_list[start_index:]:\n",
    "        count += len(l)\n",
    "        if count >= max_length:\n",
    "            return index\n",
    "        index += 1\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999849"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first 2 million characters index\n",
    "_start_index = 0\n",
    "index = get_max_index(df_movie_lines.UTTERANCE.values, 2e6, start_index=_start_index)\n",
    "count_chars(df_movie_lines.UTTERANCE.values[_start_index:index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split indices: [36222, 72819, 108282, 144941, 182428, 218582, 254564, 290490, 304712]\n",
      "36222 - 72819 num chars: 1999754\n",
      "72819 - 108282 num chars: 1999989\n",
      "108282 - 144941 num chars: 1999953\n",
      "144941 - 182428 num chars: 1999930\n",
      "182428 - 218582 num chars: 1999990\n",
      "218582 - 254564 num chars: 1999873\n",
      "254564 - 290490 num chars: 1999961\n",
      "290490 - 304712 num chars: 838927\n"
     ]
    }
   ],
   "source": [
    "# Split dataframe into <2 million chars chunks\n",
    "split_indices = []\n",
    "CHARS_PER_CHUNK = 2e6\n",
    "\n",
    "_split_index = 0\n",
    "_chars_len = count_chars(df_movie_lines.UTTERANCE.values[_split_index:])\n",
    "while (_chars_len > CHARS_PER_CHUNK):\n",
    "    _split_index = get_max_index(df_movie_lines.UTTERANCE.values, CHARS_PER_CHUNK, start_index=_split_index)\n",
    "    _chars_len = count_chars(df_movie_lines.UTTERANCE.values[_split_index:])\n",
    "    split_indices.append(_split_index)\n",
    "if (split_indices[-1] < len(df_movie_lines)-1):\n",
    "    split_indices.append(len(df_movie_lines)-1)\n",
    "\n",
    "# Indices to split the dataframe\n",
    "print(\"Split indices: {}\".format(split_indices))\n",
    "\n",
    "for _i, _index in enumerate(split_indices):\n",
    "    if _i > 0:\n",
    "        print(\"{} - {} num chars: {}\".format(split_indices[_i-1], _index, count_chars(df_movie_lines.UTTERANCE.values[split_indices[_i-1]:_index])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOVIE_LINES_CHUNK_PREFIX = \"../preprocessed_data/movie_lines_chunk_{}\"\n",
    "for i, index in enumerate(split_indices):\n",
    "    if i > 0:\n",
    "        _df = df_movie_lines.loc[split_indices[i-1]:index]\n",
    "    else:\n",
    "        _df = df_movie_lines.loc[:index]\n",
    "    _df.to_csv(MOVIE_LINES_CHUNK_PREFIX.format(i) + \".csv\")\n",
    "    _df.to_pickle(MOVIE_LINES_CHUNK_PREFIX.format(i) + \".pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53M\r\n",
      "drwxr-xr-x 2 wotan wotan 4,0K abr 14 16:35 .\r\n",
      "drwxr-xr-x 5 wotan wotan 4,0K abr 14 15:56 ..\r\n",
      "-rw-r--r-- 1 wotan wotan 3,0M abr 14 18:39 movie_lines_chunk_0.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_0.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_1.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_1.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_2.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_2.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_3.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_3.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_4.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,3M abr 14 18:39 movie_lines_chunk_4.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_5.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_5.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_6.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_6.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 3,1M abr 14 18:39 movie_lines_chunk_7.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 3,2M abr 14 18:39 movie_lines_chunk_7.pick\r\n",
      "-rw-r--r-- 1 wotan wotan 1,3M abr 14 18:39 movie_lines_chunk_8.csv\r\n",
      "-rw-r--r-- 1 wotan wotan 1,4M abr 14 18:39 movie_lines_chunk_8.pick\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../preprocessed_data -alh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Translate to Spanish\n",
    "Translate utterances to Spanish using Azure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, requests, uuid, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks to see if the Translator Text subscription key is available\n",
    "# as an environment variable. If you are setting your subscription key as a\n",
    "# string, then comment these lines out.\n",
    "if 'TRANSLATOR_TEXT_KEY' in os.environ:\n",
    "    subscriptionKey = os.environ['TRANSLATOR_TEXT_KEY']\n",
    "else:\n",
    "    print('Environment variable for TRANSLATOR_TEXT_KEY is not set.')\n",
    "    exit()\n",
    "# If you want to set your subscription key as a string, uncomment the line\n",
    "# below and add your subscription key.\n",
    "#subscriptionKey = 'put_your_key_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests elements\n",
    "\n",
    "base_url = 'https://api.cognitive.microsofttranslator.com'\n",
    "path = '/translate?api-version=3.0'\n",
    "params = '&to=es'\n",
    "constructed_url = base_url + path + params\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': subscriptionKey,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_text_azure(texts, headers, language=\"en\", destination_language=\"es\"):\n",
    "    \"\"\"\n",
    "    Translate a list of texts to one language.\n",
    "    \"\"\"\n",
    "#     body = [{\n",
    "#         'text' : text\n",
    "#     }]\n",
    "    body = [{\"text\":t, \"from\":language, \"to\":destination_language} for t in texts]\n",
    "    request = requests.post(constructed_url, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "    # Extract results\n",
    "    res = []\n",
    "    for r in response:\n",
    "        # Take the first translation\n",
    "        res.append(r[\"translations\"][0][\"text\"])\n",
    "    return res, response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Sample response__\n",
    "\n",
    "    [\n",
    "        {\n",
    "            \"detectedLanguage\": {\n",
    "                \"language\": \"en\",\n",
    "                \"score\": 1.0\n",
    "            },\n",
    "            \"translations\": [\n",
    "                {\n",
    "                    \"text\": \"Hallo Welt!\",\n",
    "                    \"to\": \"de\"\n",
    "                },\n",
    "                {\n",
    "                    \"text\": \"Salve, mondo!\",\n",
    "                    \"to\": \"it\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataframe to translate\n",
    "df = pd.read_pickle(PREPROCESSED_DATA_DIR+\"/movie_lines_chunk_0.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE_ID</th>\n",
       "      <th>CHARACTER_ID</th>\n",
       "      <th>MOVIE_ID</th>\n",
       "      <th>CHARACTER_NAME</th>\n",
       "      <th>UTTERANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L868</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>The \"real you\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L867</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>What good stuff?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L866</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I figured you'd get to the good stuff eventually.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L865</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>L864</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Me.  This endless ...blonde babble. I'm like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L863</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>What crap?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>L862</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>do you listen to this crap?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>L861</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>L860</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Then Guillermo says, \"If you go any lighter, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>L699</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You always been this selfish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>L698</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>But</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>L697</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Then that's all you had to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>L696</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Well, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>L695</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>You never wanted to go out with 'me, did you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>L694</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I was?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>L693</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I looked for you back at the party, but you al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>L663</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Tons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>L662</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Have fun tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>L578</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>I believe we share an art instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>L577</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>You know Chastity?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36193</th>\n",
       "      <td>L237899</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>I'll have to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36194</th>\n",
       "      <td>L237898</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Yes. And I'll be in some distant tree where I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>L237897</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>I'll be bait alone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>L237896</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Not for me- I'm too bulky and it's your idea, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>L237895</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>They're used to people in trees, not in a clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>L237892</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Don't they have to be?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>L237891</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>Where could it have gone? How could it get acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36200</th>\n",
       "      <td>L237888</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Nobody's seen anything like this. Lions don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36201</th>\n",
       "      <td>L237887</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>Their den?  Have you ever seen anything like t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36202</th>\n",
       "      <td>L237885</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>I got big.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36203</th>\n",
       "      <td>L237884</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>What happened to them?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36204</th>\n",
       "      <td>L237883</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>In my town, when I was little, there was a bru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36205</th>\n",
       "      <td>L237882</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>You just got hit.  The getting up is up to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36206</th>\n",
       "      <td>L237881</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>It would have been a beautiful bridge, John. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36207</th>\n",
       "      <td>L237879</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>In point of fact it didn't- but I'm convinced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36208</th>\n",
       "      <td>L237878</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>But of course yours worked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36209</th>\n",
       "      <td>L237877</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Meant to ask you- the railroad car trap. Your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36210</th>\n",
       "      <td>L237876</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>It's all right. Stay ready.  They know it's th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36211</th>\n",
       "      <td>L237875</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>Goddammit!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36212</th>\n",
       "      <td>L237874</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Only in life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36213</th>\n",
       "      <td>L237873</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>Have you ever failed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36214</th>\n",
       "      <td>L237872</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Think about something else.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36215</th>\n",
       "      <td>L237865</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>...don't know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36216</th>\n",
       "      <td>L237864</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Has it ever done that before?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36217</th>\n",
       "      <td>L237863</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>...misfire... it jammed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36218</th>\n",
       "      <td>L237858</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>You'd never force the lion to me- and nobody e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36219</th>\n",
       "      <td>L237857</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>It was probably luck- I'd rather you did the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36220</th>\n",
       "      <td>L237856</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>Samuel says you killed a lion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36221</th>\n",
       "      <td>L237855</td>\n",
       "      <td>u1116</td>\n",
       "      <td>m73</td>\n",
       "      <td>PATTERSON</td>\n",
       "      <td>I can try.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36222</th>\n",
       "      <td>L237854</td>\n",
       "      <td>u1117</td>\n",
       "      <td>m73</td>\n",
       "      <td>REDBEARD</td>\n",
       "      <td>The best way to ensure the kill when you're us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36223 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LINE_ID CHARACTER_ID MOVIE_ID CHARACTER_NAME  \\\n",
       "0        L1045           u0       m0         BIANCA   \n",
       "1        L1044           u2       m0        CAMERON   \n",
       "2         L985           u0       m0         BIANCA   \n",
       "3         L984           u2       m0        CAMERON   \n",
       "4         L925           u0       m0         BIANCA   \n",
       "5         L924           u2       m0        CAMERON   \n",
       "6         L872           u0       m0         BIANCA   \n",
       "7         L871           u2       m0        CAMERON   \n",
       "8         L870           u0       m0         BIANCA   \n",
       "9         L869           u0       m0         BIANCA   \n",
       "10        L868           u2       m0        CAMERON   \n",
       "11        L867           u0       m0         BIANCA   \n",
       "12        L866           u2       m0        CAMERON   \n",
       "13        L865           u2       m0        CAMERON   \n",
       "14        L864           u0       m0         BIANCA   \n",
       "15        L863           u2       m0        CAMERON   \n",
       "16        L862           u0       m0         BIANCA   \n",
       "17        L861           u2       m0        CAMERON   \n",
       "18        L860           u0       m0         BIANCA   \n",
       "19        L699           u2       m0        CAMERON   \n",
       "20        L698           u0       m0         BIANCA   \n",
       "21        L697           u2       m0        CAMERON   \n",
       "22        L696           u0       m0         BIANCA   \n",
       "23        L695           u2       m0        CAMERON   \n",
       "24        L694           u0       m0         BIANCA   \n",
       "25        L693           u2       m0        CAMERON   \n",
       "26        L663           u0       m0         BIANCA   \n",
       "27        L662           u2       m0        CAMERON   \n",
       "28        L578           u2       m0        CAMERON   \n",
       "29        L577           u0       m0         BIANCA   \n",
       "...        ...          ...      ...            ...   \n",
       "36193  L237899        u1116      m73      PATTERSON   \n",
       "36194  L237898        u1117      m73       REDBEARD   \n",
       "36195  L237897        u1116      m73      PATTERSON   \n",
       "36196  L237896        u1117      m73       REDBEARD   \n",
       "36197  L237895        u1116      m73      PATTERSON   \n",
       "36198  L237892        u1117      m73       REDBEARD   \n",
       "36199  L237891        u1116      m73      PATTERSON   \n",
       "36200  L237888        u1117      m73       REDBEARD   \n",
       "36201  L237887        u1116      m73      PATTERSON   \n",
       "36202  L237885        u1117      m73       REDBEARD   \n",
       "36203  L237884        u1116      m73      PATTERSON   \n",
       "36204  L237883        u1117      m73       REDBEARD   \n",
       "36205  L237882        u1116      m73      PATTERSON   \n",
       "36206  L237881        u1117      m73       REDBEARD   \n",
       "36207  L237879        u1117      m73       REDBEARD   \n",
       "36208  L237878        u1116      m73      PATTERSON   \n",
       "36209  L237877        u1117      m73       REDBEARD   \n",
       "36210  L237876        u1117      m73       REDBEARD   \n",
       "36211  L237875        u1116      m73      PATTERSON   \n",
       "36212  L237874        u1117      m73       REDBEARD   \n",
       "36213  L237873        u1116      m73      PATTERSON   \n",
       "36214  L237872        u1117      m73       REDBEARD   \n",
       "36215  L237865        u1116      m73      PATTERSON   \n",
       "36216  L237864        u1117      m73       REDBEARD   \n",
       "36217  L237863        u1116      m73      PATTERSON   \n",
       "36218  L237858        u1117      m73       REDBEARD   \n",
       "36219  L237857        u1116      m73      PATTERSON   \n",
       "36220  L237856        u1117      m73       REDBEARD   \n",
       "36221  L237855        u1116      m73      PATTERSON   \n",
       "36222  L237854        u1117      m73       REDBEARD   \n",
       "\n",
       "                                               UTTERANCE  \n",
       "0                                           They do not!  \n",
       "1                                            They do to!  \n",
       "2                                             I hope so.  \n",
       "3                                              She okay?  \n",
       "4                                              Let's go.  \n",
       "5                                                    Wow  \n",
       "6         Okay -- you're gonna need to learn how to lie.  \n",
       "7                                                     No  \n",
       "8      I'm kidding.  You know how sometimes you just ...  \n",
       "9                       Like my fear of wearing pastels?  \n",
       "10                                       The \"real you\".  \n",
       "11                                      What good stuff?  \n",
       "12     I figured you'd get to the good stuff eventually.  \n",
       "13     Thank God!  If I had to hear one more story ab...  \n",
       "14     Me.  This endless ...blonde babble. I'm like, ...  \n",
       "15                                            What crap?  \n",
       "16                           do you listen to this crap?  \n",
       "17                                                 No...  \n",
       "18     Then Guillermo says, \"If you go any lighter, y...  \n",
       "19                         You always been this selfish?  \n",
       "20                                                   But  \n",
       "21                       Then that's all you had to say.  \n",
       "22                                           Well, no...  \n",
       "23         You never wanted to go out with 'me, did you?  \n",
       "24                                                I was?  \n",
       "25     I looked for you back at the party, but you al...  \n",
       "26                                                  Tons  \n",
       "27                                     Have fun tonight?  \n",
       "28                  I believe we share an art instructor  \n",
       "29                                    You know Chastity?  \n",
       "...                                                  ...  \n",
       "36193                                      I'll have to.  \n",
       "36194  Yes. And I'll be in some distant tree where I ...  \n",
       "36195                                I'll be bait alone?  \n",
       "36196  Not for me- I'm too bulky and it's your idea, ...  \n",
       "36197  They're used to people in trees, not in a clea...  \n",
       "36198                          Don't they have to be?...  \n",
       "36199  Where could it have gone? How could it get acr...  \n",
       "36200  Nobody's seen anything like this. Lions don't ...  \n",
       "36201  Their den?  Have you ever seen anything like t...  \n",
       "36202                                         I got big.  \n",
       "36203                             What happened to them?  \n",
       "36204  In my town, when I was little, there was a bru...  \n",
       "36205  You just got hit.  The getting up is up to you...  \n",
       "36206  It would have been a beautiful bridge, John. I...  \n",
       "36207  In point of fact it didn't- but I'm convinced ...  \n",
       "36208                        But of course yours worked.  \n",
       "36209  Meant to ask you- the railroad car trap. Your ...  \n",
       "36210  It's all right. Stay ready.  They know it's th...  \n",
       "36211                                         Goddammit!  \n",
       "36212                                    Only in life...  \n",
       "36213                              Have you ever failed?  \n",
       "36214                        Think about something else.  \n",
       "36215                                   ...don't know...  \n",
       "36216                      Has it ever done that before?  \n",
       "36217                         ...misfire... it jammed...  \n",
       "36218  You'd never force the lion to me- and nobody e...  \n",
       "36219  It was probably luck- I'd rather you did the s...  \n",
       "36220                     Samuel says you killed a lion.  \n",
       "36221                                         I can try.  \n",
       "36222  The best way to ensure the kill when you're us...  \n",
       "\n",
       "[36223 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LINE_ID                                                        L866\n",
       "CHARACTER_ID                                                     u2\n",
       "MOVIE_ID                                                         m0\n",
       "CHARACTER_NAME                                              CAMERON\n",
       "UTTERANCE         I figured you'd get to the good stuff eventually.\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['They do not!', 'They do to!', 'I hope so.', 'She okay?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_texts = df.UTTERANCE.values[:4]\n",
    "_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2 = translate_text_azure(_texts, headers, language=\"en\", destination_language=\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'detectedLanguage': {'language': 'en', 'score': 1.0},\n",
       "  'translations': [{'text': '¡ No lo hacen!', 'to': 'es'}]},\n",
       " {'detectedLanguage': {'language': 'en', 'score': 1.0},\n",
       "  'translations': [{'text': '¡ Lo hacen!', 'to': 'es'}]},\n",
       " {'detectedLanguage': {'language': 'en', 'score': 1.0},\n",
       "  'translations': [{'text': 'Eso espero.', 'to': 'es'}]},\n",
       " {'detectedLanguage': {'language': 'en', 'score': 1.0},\n",
       "  'translations': [{'text': '¿Está bien?', 'to': 'es'}]}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Translator(object):\n",
    "    _SEPARATOR = \"$___$___$\"\n",
    "    \n",
    "    def __init__(self, language=\"en\", destination_language=\"es\"):\n",
    "        # Checks to see if the Translator Text subscription key is available\n",
    "        # as an environment variable. If you are setting your subscription key as a\n",
    "        # string, then comment these lines out.\n",
    "        if 'TRANSLATOR_TEXT_KEY' in os.environ:\n",
    "            subscriptionKey = os.environ['TRANSLATOR_TEXT_KEY']\n",
    "        else:\n",
    "            print('Environment variable for TRANSLATOR_TEXT_KEY is not set.')\n",
    "            exit()\n",
    "\n",
    "        # If you want to set your subscription key as a string, uncomment the line\n",
    "        # below and add your subscription key.\n",
    "        #subscriptionKey = 'put_your_key_here'\n",
    "        \n",
    "        base_url = 'https://api.cognitive.microsofttranslator.com'\n",
    "        path = '/translate?api-version=3.0'\n",
    "        params = '&to=es'\n",
    "        self.constructed_url = base_url + path + params\n",
    "\n",
    "        self.headers = {\n",
    "            'Ocp-Apim-Subscription-Key': subscriptionKey,\n",
    "            'Content-type': 'application/json',\n",
    "            'X-ClientTraceId': str(uuid.uuid4())\n",
    "        }\n",
    "        \n",
    "    def translate_text_azure(self, texts, log_file=\"./translation_log\"):\n",
    "        \"\"\"\n",
    "        Translate a list of texts to one language.\n",
    "        Args:\n",
    "            texts: list of texts\n",
    "            translation_log: file to append translation results\n",
    "        \"\"\"\n",
    "    #     body = [{\n",
    "    #         'text' : text\n",
    "    #     }]\n",
    "        body = [{\"text\":t} for t in texts]\n",
    "        request = requests.post(self.constructed_url, headers=self.headers, json=body)\n",
    "        response = request.json()\n",
    "        # Extract results\n",
    "        res = []\n",
    "        if log_file is not None:\n",
    "            with open(log_file + \"_raw\", \"a\") as f:\n",
    "                for i, r in enumerate(response):\n",
    "                    f.write(\"{} {} {}\\n\".format(texts[i], Translator._SEPARATOR, r))\n",
    "        for r in response:\n",
    "            # Take the first translation\n",
    "            res.append(r[\"translations\"][0][\"text\"])\n",
    "        if log_file is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                for i, r in enumerate(res):\n",
    "                    f.write(\"{} {} {}\\n\".format(texts[i], Translator._SEPARATOR, r))\n",
    "            with open(log_file + \"_raw\", \"a\") as f:\n",
    "                for i, r in enumerate(response):\n",
    "                    f.write(\"{} {} {}\\n\".format(texts[i], Translator._SEPARATOR, r))\n",
    "        return res, response     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(language=\"en\", destination_language=\"es\")\n",
    "\n",
    "# r1, r2 = translator.translate_text_azure(_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translations = []\n",
    "# complete_responses = []\n",
    "# _offset = 10035\n",
    "# for s in tqdm(df.UTTERANCE.values[_offset:]):\n",
    "#     r1, r2 = translator.translate_text_azure([s])\n",
    "#     translations.append(r1)\n",
    "#     complete_responses.append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-caeb30d1279d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m__num_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_text_azure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUTTERANCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0m__indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-90190ab5862c>\u001b[0m in \u001b[0;36mtranslate_text_azure\u001b[0;34m(self, texts, log_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Take the first translation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"translations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "_offset = 15346\n",
    "__indices = []\n",
    "__num_steps = 20\n",
    "for i in range(_offset, len(df)):\n",
    "    if len(__indices) >= __num_steps:    \n",
    "        r1, r2 = translator.translate_text_azure(df.UTTERANCE.values[__indices])\n",
    "        __indices = []\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        __indices.append(i)\n",
    "    \n",
    "if len(__indices > 0):\n",
    "        r1, r2 = translator.translate_text_azure(__indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df[\"UTTERANCE_ES\"] = translations\n",
    "# df.to_csv(PREPROCESSED_DATA_DIR + \"/movie_lines_chunk_0_translated.csv\")\n",
    "# df.to_pickle(PREPROCESSED_DATA_DIR + \"/movie_lines_chunk_0_translated.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
